{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DSdBL-jktGhyl5iKWdyHZCD9bWK9xu_g",
      "authorship_tag": "ABX9TyPNtTszF5ZtRFImyCGoKrHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashong-Nartey/Hyperspectral-Image-Classification-/blob/main/HSI_ContextualNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf85K9PZUoNR",
        "outputId": "e1f666dd-2704-4dc7-87c7-bd610917e4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/geniter.py /content/drive/MyDrive/HSI/\n",
        "!cp -r /content/utils.py /content/drive/MyDrive/HSI/\n",
        "!cp -r /content/record.py /content/drive/MyDrive/HSI/\n",
        "!cp -r /content/dataset/ /content/drive/MyDrive/HSI/"
      ],
      "metadata": {
        "id": "RtPGqJZnZhZU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spectral==0.20\n",
        "!pip install torch-summary==1.2.0\n",
        "!pip install torch-optimizer==0.0.1a12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM75-GjobR01",
        "outputId": "9dc00426-8245-4e27-c717-c0bad7593eff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spectral==0.20\n",
            "  Downloading spectral-0.20.tar.gz (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from spectral==0.20) (1.21.6)\n",
            "Building wheels for collected packages: spectral\n",
            "  Building wheel for spectral (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectral: filename=spectral-0.20-py3-none-any.whl size=183936 sha256=684903086ae78c0d2d6935ab35594485ed31dd42bd80168d4e316a1af4f203d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/48/cd/916a9ac128df99f05cf8f631433f3b611044634c5ac0db3228\n",
            "Successfully built spectral\n",
            "Installing collected packages: spectral\n",
            "Successfully installed spectral-0.20\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-summary==1.2.0\n",
            "  Downloading torch_summary-1.2.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-optimizer==0.0.1a12\n",
            "  Downloading torch_optimizer-0.0.1a12-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from torch-optimizer==0.0.1a12) (1.13.0+cu116)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.1.0->torch-optimizer==0.0.1a12) (4.4.0)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.0.1a12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import collections\n",
        "import math\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn import metrics, preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import geniter\n",
        "import record\n",
        "import torch_optimizer as optim2\n",
        "import utils\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "Q987BQ4rcEde"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM_DATASET = 'SV'  # UP,IN,SV, KSC\n",
        "PARAM_EPOCH = 200\n",
        "PARAM_ITER = 3\n",
        "PATCH_SIZE = 4\n",
        "PARAM_VAL = 0.9\n",
        "PARAM_OPTIM = 'adam'\n",
        "PARAM_KERNEL_SIZE = 24"
      ],
      "metadata": {
        "id": "153ERBxwcRtA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# for Monte Carlo runs\n",
        "seeds = [1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341]\n",
        "ensemble = 1\n",
        "\n",
        "global Dataset  # UP,IN,SV, KSC\n",
        "dataset = PARAM_DATASET  # input('Please input the name of Dataset(IN, UP, SV, KSC):')\n",
        "Dataset = dataset.upper()\n",
        "\n",
        "\n",
        "def load_dataset(Dataset, split=0.9):\n",
        "    data_path = '/content/drive/MyDrive/HSI/dataset/'\n",
        "    if Dataset == 'IN':\n",
        "        mat_data = sio.loadmat(data_path + 'Indian_pines_corrected.mat')\n",
        "        mat_gt = sio.loadmat(data_path + 'Indian_pines_gt.mat')\n",
        "        data_hsi = mat_data['indian_pines_corrected']\n",
        "        gt_hsi = mat_gt['indian_pines_gt']\n",
        "        K = 200\n",
        "        TOTAL_SIZE = 10249\n",
        "        VALIDATION_SPLIT = split\n",
        "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
        "\n",
        "    if Dataset == 'UP':\n",
        "        uPavia = sio.loadmat(data_path + 'PaviaU.mat')\n",
        "        gt_uPavia = sio.loadmat(data_path + 'PaviaU_gt.mat')\n",
        "        data_hsi = uPavia['paviaU']\n",
        "        gt_hsi = gt_uPavia['paviaU_gt']\n",
        "        K = 103\n",
        "        TOTAL_SIZE = 42776\n",
        "        VALIDATION_SPLIT = split\n",
        "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
        "\n",
        "    if Dataset == 'SV':\n",
        "        SV = sio.loadmat(data_path + 'Salinas_corrected.mat')\n",
        "        gt_SV = sio.loadmat(data_path + 'Salinas_gt.mat')\n",
        "        data_hsi = SV['salinas_corrected']\n",
        "        gt_hsi = gt_SV['salinas_gt']\n",
        "        K = 15\n",
        "        TOTAL_SIZE = 54129\n",
        "        VALIDATION_SPLIT = split\n",
        "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
        "\n",
        "    if Dataset == 'KSC':\n",
        "        SV = sio.loadmat(data_path + 'KSC.mat')\n",
        "        gt_SV = sio.loadmat(data_path + 'KSC_gt.mat')\n",
        "        data_hsi = SV['KSC']\n",
        "        gt_hsi = gt_SV['KSC_gt']\n",
        "        K = data_hsi.shape[2]\n",
        "        TOTAL_SIZE = 5211\n",
        "        VALIDATION_SPLIT = split\n",
        "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
        "\n",
        "    shapeor = data_hsi.shape\n",
        "    data_hsi = data_hsi.reshape(-1, data_hsi.shape[-1])\n",
        "    data_hsi = PCA(n_components=K).fit_transform(data_hsi)\n",
        "    shapeor = np.array(shapeor)\n",
        "    shapeor[-1] = K\n",
        "    data_hsi = data_hsi.reshape(shapeor)\n",
        "\n",
        "    return data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT\n",
        "\n",
        "\n",
        "# # Pytorch Data Loader Creation\n",
        "\n",
        "data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT = load_dataset(\n",
        "    Dataset, PARAM_VAL)\n",
        "print(data_hsi.shape)\n",
        "image_x, image_y, BAND = data_hsi.shape\n",
        "data = data_hsi.reshape(\n",
        "    np.prod(data_hsi.shape[:2]), np.prod(data_hsi.shape[2:]))\n",
        "gt = gt_hsi.reshape(np.prod(gt_hsi.shape[:2]), )\n",
        "CLASSES_NUM = max(gt)\n",
        "print('The class numbers of the HSI data is:', CLASSES_NUM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJOy5riIcxSO",
        "outputId": "7740f4bb-5563-4cba-ba8d-bef7771faa4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 217, 15)\n",
            "The class numbers of the HSI data is: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----Importing Setting Parameters-----')\n",
        "ITER = PARAM_ITER\n",
        "PATCH_LENGTH = PATCH_SIZE\n",
        "lr, num_epochs, batch_size = 0.001, 200, 32\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "img_rows = 2 * PATCH_LENGTH + 1\n",
        "img_cols = 2 * PATCH_LENGTH + 1\n",
        "img_channels = data_hsi.shape[2]\n",
        "INPUT_DIMENSION = data_hsi.shape[2]\n",
        "ALL_SIZE = data_hsi.shape[0] * data_hsi.shape[1]\n",
        "VAL_SIZE = int(TRAIN_SIZE)\n",
        "TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
        "\n",
        "KAPPA = []\n",
        "OA = []\n",
        "AA = []\n",
        "TRAINING_TIME = []\n",
        "TESTING_TIME = []\n",
        "ELEMENT_ACC = np.zeros((ITER, CLASSES_NUM))\n",
        "\n",
        "data = preprocessing.scale(data)\n",
        "data_ = data.reshape(data_hsi.shape[0], data_hsi.shape[1], data_hsi.shape[2])\n",
        "whole_data = data_\n",
        "padded_data = np.lib.pad(\n",
        "    whole_data, ((PATCH_LENGTH, PATCH_LENGTH), (PATCH_LENGTH, PATCH_LENGTH),\n",
        "                 (0, 0)),\n",
        "    'constant',\n",
        "    constant_values=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkrsMqCrc9M9",
        "outputId": "6bd6d62a-1c90-494d-8aca-760811952ac6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Importing Setting Parameters-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Model\n",
        "\n",
        "class LeeEtAl(nn.Module):\n",
        "    \"\"\"\n",
        "    CONTEXTUAL DEEP CNN BASED HYPERSPECTRAL CLASSIFICATION\n",
        "    Hyungtae Lee and Heesung Kwon\n",
        "    IGARSS 2016\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def weight_init(m):\n",
        "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "    def __init__(self, in_channels, n_classes):\n",
        "        super(LeeEtAl, self).__init__()\n",
        "        # The first convolutional layer applied to the input hyperspectral\n",
        "        # image uses an inception module that locally convolves the input\n",
        "        # image with two convolutional filters with different sizes\n",
        "        # (1x1xB and 3x3xB where B is the number of spectral bands)\n",
        "        self.conv_3x3 = nn.Conv3d(\n",
        "            1, 128, (3, 3, in_channels), stride=(1, 1, 2), padding=(1, 1, 0))\n",
        "        self.conv_1x1 = nn.Conv3d(\n",
        "            1, 128, (1, 1, in_channels), stride=(1, 1, 1), padding=0)\n",
        "        self.name = 'LeeEtAl'\n",
        "\n",
        "        # We use two modules from the residual learning approach\n",
        "        # Residual block 1\n",
        "        self.conv1 = nn.Conv2d(256, 128, (1, 1))\n",
        "        self.conv2 = nn.Conv2d(128, 128, (1, 1))\n",
        "        self.conv3 = nn.Conv2d(128, 128, (1, 1))\n",
        "\n",
        "        # Residual block 2\n",
        "        self.conv4 = nn.Conv2d(128, 128, (1, 1))\n",
        "        self.conv5 = nn.Conv2d(128, 128, (1, 1))\n",
        "\n",
        "        # The layer combination in the last three convolutional layers\n",
        "        # is the same as the fully connected layers of Alexnet\n",
        "        self.conv6 = nn.Conv2d(128, 128, (1, 1))\n",
        "        self.conv7 = nn.Conv2d(128, 128, (1, 1))\n",
        "        self.conv8 = nn.Conv2d(128, n_classes, (9, 9))\n",
        "\n",
        "        self.lrn1 = nn.LocalResponseNorm(256)\n",
        "        self.lrn2 = nn.LocalResponseNorm(128)\n",
        "\n",
        "        # The 7 th and 8 th convolutional layers have dropout in training\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.apply(self.weight_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Inception module\n",
        "        x_3x3 = self.conv_3x3(x)\n",
        "        x_1x1 = self.conv_1x1(x)\n",
        "        x = torch.cat([x_3x3, x_1x1], dim=1)\n",
        "        # Remove the third dimension of the tensor\n",
        "        x = torch.squeeze(x)\n",
        "\n",
        "        # Local Response Normalization\n",
        "        x = F.relu(self.lrn1(x))\n",
        "\n",
        "        # First convolution\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        # Local Response Normalization\n",
        "        x = F.relu(self.lrn2(x))\n",
        "\n",
        "        # First residual block\n",
        "        x_res = F.relu(self.conv2(x))\n",
        "        x_res = self.conv3(x_res)\n",
        "        x = F.relu(x + x_res)\n",
        "\n",
        "        # Second residual block\n",
        "        x_res = F.relu(self.conv4(x))\n",
        "        x_res = self.conv5(x_res)\n",
        "        x = F.relu(x + x_res)\n",
        "\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv8(x)\n",
        "        x = x.squeeze(2).squeeze(2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_oguie3MdQHW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeeEtAl(BAND, CLASSES_NUM).cuda()\n",
        "\n",
        "summary(model, input_data=(1, img_rows, img_cols, BAND), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "A74ybmghd3lU",
        "outputId": "c328c03a-1d1b-4682-fe66-bdb900ee0e5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7bc6e158b02a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeeEtAl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBAND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBAND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    }
  ]
}